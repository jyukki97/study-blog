---
title: "WebSocket + gRPC ì‹¤ì‹œê°„ ìŒì„±ì²˜ë¦¬ ì„œë¹„ìŠ¤"
date: 2025-11-03
draft: true
topic: "Architecture"
topic_icon: "ğŸ—ï¸"
topic_description: "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë° ì„¤ê³„ íŒ¨í„´"
tags: ["WebSocket", "gRPC", "STT", "Real-time", "Architecture"]
categories: ["Development", "Learning"]
description: "STT ìŠ¤íŠ¸ë¦¬ë° êµ¬ì¡°, backpressure ì œì–´, ì‹¤ì‹œê°„ latency ê´€ë¦¬"
---

> **í•™ìŠµ ëª©í‘œ**: WebSocketê³¼ gRPCë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬ ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í•˜ê³ , Backpressureì™€ ì§€ì—°ì‹œê°„ ê´€ë¦¬ ì „ëµì„ í•™ìŠµí•œë‹¤.

## ğŸ¤ í”„ë¡œì íŠ¸ ë°°ê²½

### ìš”êµ¬ì‚¬í•­

ìŒì„± ì¸ì‹(STT) ì„œë¹„ìŠ¤ë¥¼ ì›¹ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì œê³µ:
- âœ… ì‚¬ìš©ì ìŒì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„œë²„ì— ì „ì†¡
- âœ… STT ì—”ì§„ì—ì„œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
- âœ… ì¤‘ê°„ ê²°ê³¼(partial)ì™€ ìµœì¢… ê²°ê³¼(final) ì‹¤ì‹œê°„ ë°˜í™˜
- âœ… ì§€ì—°ì‹œê°„ < 200ms (ì²´ê° ì§€ì—° ìµœì†Œí™”)
- âœ… ë™ì‹œ ì‚¬ìš©ì 1,000ëª… ì´ìƒ ì²˜ë¦¬

### ê¸°ìˆ  ì„ íƒ

| êµ¬ê°„ | í”„ë¡œí† ì½œ | ì´ìœ  |
|------|---------|------|
| **Browser â†” Gateway** | WebSocket | ë¸Œë¼ìš°ì € ì§€ì›, ì–‘ë°©í–¥ í†µì‹  |
| **Gateway â†” STT Engine** | gRPC Streaming | íš¨ìœ¨ì ì¸ ë°”ì´ë„ˆë¦¬ í”„ë¡œí† ì½œ, ìŠ¤íŠ¸ë¦¬ë° ì§€ì› |

---

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚
â”‚  (Web App)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ WebSocket
       â”‚ Audio Chunks (16kHz PCM)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gateway Server (Node.js)   â”‚
â”‚  - WebSocket Handler          â”‚
â”‚  - gRPC Client                â”‚
â”‚  - Backpressure Control       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ gRPC Streaming
       â”‚ StreamingRecognize
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    STT Engine (Python)        â”‚
â”‚  - gRPC Server                â”‚
â”‚  - Wav2Vec 2.0 / Whisper      â”‚
â”‚  - GPU Processing             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ STT Results
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Database   â”‚
â”‚   (MongoDB)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ WebSocket êµ¬í˜„

### Browser â†’ Gateway

**í´ë¼ì´ì–¸íŠ¸ (JavaScript)**:

```javascript
class RealtimeSTTClient {
    constructor(wsUrl) {
        this.ws = new WebSocket(wsUrl);
        this.audioContext = new AudioContext({ sampleRate: 16000 });
        this.mediaStream = null;
        this.processor = null;
    }

    async startRecording() {
        // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
        this.mediaStream = await navigator.mediaDevices.getUserMedia({
            audio: {
                channelCount: 1,
                sampleRate: 16000,
                echoCancellation: true,
                noiseSuppression: true,
            }
        });

        const source = this.audioContext.createMediaStreamSource(this.mediaStream);

        // AudioWorklet ì‚¬ìš© (Web Workersì—ì„œ ì‹¤í–‰)
        await this.audioContext.audioWorklet.addModule('/audio-processor.js');
        this.processor = new AudioWorkletNode(this.audioContext, 'audio-processor');

        // ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ 
        this.processor.port.onmessage = (event) => {
            const audioData = event.data;  // Float32Array
            this.sendAudioChunk(audioData);
        };

        source.connect(this.processor);
        this.processor.connect(this.audioContext.destination);
    }

    sendAudioChunk(float32Array) {
        // Float32 â†’ Int16 ë³€í™˜ (gRPC ì „ì†¡ìš©)
        const int16Array = new Int16Array(float32Array.length);
        for (let i = 0; i < float32Array.length; i++) {
            const s = Math.max(-1, Math.min(1, float32Array[i]));
            int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }

        if (this.ws.readyState === WebSocket.OPEN) {
            this.ws.send(int16Array.buffer);
        }
    }

    onPartialResult(callback) {
        this.ws.onmessage = (event) => {
            const result = JSON.parse(event.data);
            if (result.is_final) {
                callback(result.text, true);
            } else {
                callback(result.text, false);  // partial result
            }
        };
    }

    stopRecording() {
        if (this.processor) {
            this.processor.disconnect();
        }
        if (this.mediaStream) {
            this.mediaStream.getTracks().forEach(track => track.stop());
        }
        this.ws.close();
    }
}

// ì‚¬ìš© ì˜ˆì‹œ
const sttClient = new RealtimeSTTClient('wss://api.example.com/stt');
await sttClient.startRecording();

sttClient.onPartialResult((text, isFinal) => {
    if (isFinal) {
        console.log('Final:', text);
        document.getElementById('final-result').textContent += text + ' ';
    } else {
        console.log('Partial:', text);
        document.getElementById('partial-result').textContent = text;
    }
});
```

### Gateway Server (Node.js + WebSocket)

```javascript
import WebSocket, { WebSocketServer } from 'ws';
import { createSTTClient } from './grpc-client.js';

const wss = new WebSocketServer({ port: 8080 });

wss.on('connection', async (ws, req) => {
    const sessionId = generateSessionId();
    console.log(`New connection: ${sessionId}`);

    // gRPC ìŠ¤íŠ¸ë¦¼ ìƒì„±
    const grpcStream = createSTTClient();

    // gRPC â†’ WebSocket íŒŒì´í”„
    grpcStream.on('data', (response) => {
        const result = {
            text: response.transcript,
            is_final: response.is_final,
            confidence: response.confidence,
        };
        ws.send(JSON.stringify(result));
    });

    grpcStream.on('error', (error) => {
        console.error('gRPC error:', error);
        ws.close(1011, 'STT engine error');
    });

    // WebSocket â†’ gRPC íŒŒì´í”„
    ws.on('message', (audioData) => {
        // Backpressure ì²´í¬
        if (!grpcStream.write({
            audio_content: audioData,
            session_id: sessionId,
        })) {
            // ë²„í¼ê°€ ê°€ë“ ì°¸ â†’ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì†ë„ ì¡°ì ˆ ìš”ì²­
            ws.send(JSON.stringify({ type: 'slow_down' }));
        }
    });

    ws.on('close', () => {
        console.log(`Connection closed: ${sessionId}`);
        grpcStream.end();
    });
});
```

---

## ğŸš€ gRPC Streaming êµ¬í˜„

### Proto ì •ì˜

```protobuf
syntax = "proto3";

package stt;

service SpeechToText {
  rpc StreamingRecognize(stream StreamingRecognizeRequest)
      returns (stream StreamingRecognizeResponse);
}

message StreamingRecognizeRequest {
  bytes audio_content = 1;
  string session_id = 2;
  AudioConfig audio_config = 3;
}

message AudioConfig {
  int32 sample_rate = 1;  // 16000
  int32 channels = 2;      // 1 (mono)
  string encoding = 3;     // "PCM_INT16"
}

message StreamingRecognizeResponse {
  string transcript = 1;
  bool is_final = 2;
  float confidence = 3;
  int64 audio_duration_ms = 4;
}
```

### gRPC Client (Node.js)

```javascript
import grpc from '@grpc/grpc-js';
import protoLoader from '@grpc/proto-loader';

const packageDefinition = protoLoader.loadSync('stt.proto');
const sttProto = grpc.loadPackageDefinition(packageDefinition).stt;

export function createSTTClient() {
    const client = new sttProto.SpeechToText(
        'localhost:50051',
        grpc.credentials.createInsecure()
    );

    const stream = client.StreamingRecognize();

    // ì²« ë²ˆì§¸ ë©”ì‹œì§€ì— config í¬í•¨
    stream.write({
        session_id: generateSessionId(),
        audio_config: {
            sample_rate: 16000,
            channels: 1,
            encoding: 'PCM_INT16',
        },
    });

    return stream;
}
```

### gRPC Server (Python + Wav2Vec)

```python
import grpc
from concurrent import futures
import stt_pb2
import stt_pb2_grpc
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
import torch
import numpy as np

class STTService(stt_pb2_grpc.SpeechToTextServicer):
    def __init__(self):
        self.processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base-960h")
        self.model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-base-960h")
        self.model.eval()
        if torch.cuda.is_available():
            self.model = self.model.cuda()

    def StreamingRecognize(self, request_iterator, context):
        audio_buffer = bytearray()
        chunk_duration_ms = 200  # 200ms ë‹¨ìœ„ë¡œ ì²˜ë¦¬

        for request in request_iterator:
            audio_buffer.extend(request.audio_content)

            # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ëª¨ì´ë©´ ì²˜ë¦¬
            required_bytes = int(16000 * 2 * chunk_duration_ms / 1000)
            if len(audio_buffer) >= required_bytes:
                chunk = audio_buffer[:required_bytes]
                audio_buffer = audio_buffer[required_bytes:]

                # Int16 â†’ Float32 ë³€í™˜
                audio_np = np.frombuffer(chunk, dtype=np.int16).astype(np.float32) / 32768.0

                # STT ì¶”ë¡ 
                inputs = self.processor(audio_np, sampling_rate=16000, return_tensors="pt")
                with torch.no_grad():
                    logits = self.model(inputs.input_values.cuda()).logits

                predicted_ids = torch.argmax(logits, dim=-1)
                transcription = self.processor.batch_decode(predicted_ids)[0]

                # Partial result ì „ì†¡
                yield stt_pb2.StreamingRecognizeResponse(
                    transcript=transcription,
                    is_final=False,
                    confidence=0.8,
                )

        # ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬ (Final result)
        if len(audio_buffer) > 0:
            audio_np = np.frombuffer(audio_buffer, dtype=np.int16).astype(np.float32) / 32768.0
            inputs = self.processor(audio_np, sampling_rate=16000, return_tensors="pt")
            with torch.no_grad():
                logits = self.model(inputs.input_values.cuda()).logits
            predicted_ids = torch.argmax(logits, dim=-1)
            transcription = self.processor.batch_decode(predicted_ids)[0]

            yield stt_pb2.StreamingRecognizeResponse(
                transcript=transcription,
                is_final=True,
                confidence=0.95,
            )

def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    stt_pb2_grpc.add_SpeechToTextServicer_to_server(STTService(), server)
    server.add_insecure_port('[::]:50051')
    server.start()
    print("gRPC server started on port 50051")
    server.wait_for_termination()

if __name__ == '__main__':
    serve()
```

---

## âš–ï¸ Backpressure ì œì–´

### ë¬¸ì œ ìƒí™©

**Browser â†’ GatewayëŠ” ë¹ ë¥´ì§€ë§Œ, Gateway â†’ STT Engineì´ ëŠë¦° ê²½ìš°**:
- GPU ì²˜ë¦¬ ì†ë„ < ì˜¤ë””ì˜¤ ìœ ì… ì†ë„
- ë©”ëª¨ë¦¬ ë²„í¼ í­ë°œ â†’ OOM

### í•´ê²° ë°©ë²•

#### 1. Flow Control (gRPC)

```javascript
// Gatewayì—ì„œ gRPC write ê²°ê³¼ í™•ì¸
let canSend = true;

ws.on('message', (audioData) => {
    if (!canSend) {
        // ë²„í¼ê°€ ê°€ë“ ì°¸ â†’ ë“œë¡­í•˜ê±°ë‚˜ íì‰
        console.warn('Backpressure detected, dropping frame');
        return;
    }

    canSend = grpcStream.write({
        audio_content: audioData,
    });

    if (!canSend) {
        // drain ì´ë²¤íŠ¸ ëŒ€ê¸°
        grpcStream.once('drain', () => {
            canSend = true;
        });
    }
});
```

#### 2. Adaptive Sampling

```javascript
// í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì „ì†¡ ì†ë„ ì¡°ì ˆ
class AdaptiveSTTClient {
    constructor() {
        this.sendInterval = 100;  // ì´ˆê¸° 100ms
        this.lastSlowDownTime = 0;
    }

    onSlowDown() {
        // ì„œë²„ì—ì„œ slow_down ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œ
        this.sendInterval = Math.min(this.sendInterval * 1.5, 500);
        console.log(`Slowing down to ${this.sendInterval}ms interval`);
    }

    onNormal() {
        // ì •ìƒ ìƒíƒœë¡œ ë³µêµ¬
        this.sendInterval = Math.max(this.sendInterval * 0.9, 100);
    }
}
```

#### 3. Buffer Limiting

```javascript
const MAX_BUFFER_SIZE = 1024 * 1024;  // 1MB

let bufferSize = 0;

ws.on('message', (audioData) => {
    bufferSize += audioData.length;

    if (bufferSize > MAX_BUFFER_SIZE) {
        console.error('Buffer overflow! Closing connection.');
        ws.close(1008, 'Buffer overflow');
        return;
    }

    grpcStream.write({
        audio_content: audioData,
    }, () => {
        bufferSize -= audioData.length;  // ì „ì†¡ ì™„ë£Œ ì‹œ ê°ì†Œ
    });
});
```

---

## â±ï¸ Latency ìµœì í™”

### ì¸¡ì • ì§€í‘œ

| êµ¬ê°„ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|----------|
| **Browser â†’ Gateway** | < 20ms | WebSocket RTT |
| **Gateway â†’ STT Engine** | < 50ms | gRPC ì™•ë³µ ì‹œê°„ |
| **STT Inference** | < 100ms | GPU ì²˜ë¦¬ ì‹œê°„ |
| **Total E2E** | < 200ms | ì‚¬ìš©ì ìŒì„± â†’ ê²°ê³¼ í‘œì‹œ |

### ìµœì í™” ì „ëµ

#### 1. Chunk Size ì¡°ì •

```python
# ì‘ì€ ì²­í¬ = ë‚®ì€ ì§€ì—°, ë‚®ì€ ì •í™•ë„
CHUNK_DURATION_MS = 200  # 200ms

# í° ì²­í¬ = ë†’ì€ ì§€ì—°, ë†’ì€ ì •í™•ë„
CHUNK_DURATION_MS = 1000  # 1ì´ˆ

# ìµœì ê°’ ì°¾ê¸° (ì‹¤í—˜ì  íŠœë‹)
CHUNK_DURATION_MS = 300  # 300ms (ì ˆì¶©ì•ˆ)
```

#### 2. GPU Batching

```python
class BatchedSTTEngine:
    def __init__(self, batch_size=4, max_wait_ms=50):
        self.batch_size = batch_size
        self.max_wait_ms = max_wait_ms
        self.queue = []

    async def process_stream(self, audio_chunk):
        self.queue.append(audio_chunk)

        # ë°°ì¹˜ í¬ê¸° ë„ë‹¬ or íƒ€ì„ì•„ì›ƒ
        if len(self.queue) >= self.batch_size or self.is_timeout():
            batch = self.queue[:self.batch_size]
            self.queue = self.queue[self.batch_size:]

            # ë°°ì¹˜ ì²˜ë¦¬ (GPU íš¨ìœ¨ ì¦ê°€)
            results = self.model.batch_infer(batch)
            return results
```

#### 3. Warm-up & Keep-alive

```python
# ëª¨ë¸ warm-up (ì²« ìš”ì²­ ì§€ì—° ì œê±°)
def warm_up_model():
    dummy_audio = np.zeros(16000, dtype=np.float32)  # 1ì´ˆ ë¬´ìŒ
    inputs = processor(dummy_audio, sampling_rate=16000, return_tensors="pt")
    with torch.no_grad():
        model(inputs.input_values.cuda())
    print("Model warmed up!")

warm_up_model()

# gRPC Keep-alive
server = grpc.server(
    futures.ThreadPoolExecutor(max_workers=10),
    options=[
        ('grpc.keepalive_time_ms', 10000),
        ('grpc.keepalive_timeout_ms', 5000),
    ]
)
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Prometheus Metrics

```javascript
import { Counter, Histogram } from 'prom-client';

const audioChunksReceived = new Counter({
    name: 'stt_audio_chunks_received_total',
    help: 'Total audio chunks received from clients',
});

const sttLatency = new Histogram({
    name: 'stt_latency_seconds',
    help: 'STT processing latency',
    buckets: [0.05, 0.1, 0.2, 0.5, 1.0],
});

ws.on('message', (audioData) => {
    audioChunksReceived.inc();

    const startTime = Date.now();
    grpcStream.write({ audio_content: audioData }, () => {
        sttLatency.observe((Date.now() - startTime) / 1000);
    });
});
```

### Grafana Dashboard

- **WebSocket Connections**: ë™ì‹œ ì—°ê²° ìˆ˜
- **Audio Throughput**: ì´ˆë‹¹ ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (MB/s)
- **STT Latency**: P50, P95, P99 ì§€ì—°ì‹œê°„
- **Error Rate**: WebSocket/gRPC ì—ëŸ¬ìœ¨

---

## ğŸ’¡ ë°°ìš´ êµí›ˆ

### 1. Partial Resultsì˜ ì¤‘ìš”ì„±

ì´ˆê¸°ì—ëŠ” ìµœì¢… ê²°ê³¼ë§Œ ì „ì†¡í–ˆì§€ë§Œ, ì‚¬ìš©ì ê²½í—˜ì´ ë‚˜ë¹´ìŠµë‹ˆë‹¤.
- âœ… Partial resultsë¡œ ì¦‰ê°ì ì¸ í”¼ë“œë°± ì œê³µ
- âœ… ì‚¬ìš©ìê°€ ì¤‘ê°„ ê²°ê³¼ë¥¼ ë³´ê³  ë°œí™” ì¡°ì • ê°€ëŠ¥

### 2. Backpressureë¥¼ ë¬´ì‹œí•˜ë©´ ì•ˆ ëœë‹¤

ì´ˆê¸° ë²„ì „ì—ì„œ backpressureë¥¼ ì²˜ë¦¬í•˜ì§€ ì•Šì•„ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°œìƒ.
- âœ… gRPC `write()` ë°˜í™˜ê°’ í™•ì¸ í•„ìˆ˜
- âœ… Buffer í¬ê¸° ì œí•œ í•„ìš”

### 3. GPU Batchingì˜ íš¨ê³¼

ê°œë³„ ìš”ì²­ ì²˜ë¦¬ ëŒ€ë¹„ **5ë°° ì²˜ë¦¬ëŸ‰ ì¦ê°€**.
- Throughput: 10 req/s â†’ 50 req/s
- Latency ì¦ê°€: 50ms (í—ˆìš© ë²”ìœ„)

---

## ğŸ“‹ í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] WebSocket ì–‘ë°©í–¥ í†µì‹  ì´í•´
- [ ] gRPC Streaming êµ¬í˜„ ê°€ëŠ¥
- [ ] Backpressure ì œì–´ ë°©ë²• 3ê°€ì§€ ì´ìƒ
- [ ] Latency ìµœì í™” ì „ëµ ì ìš© ê°€ëŠ¥
- [ ] Prometheusë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ êµ¬ì„±

---

## ğŸ”— ì°¸ê³  ìë£Œ

- [gRPC Streaming Guide](https://grpc.io/docs/languages/node/basics/#server-side-streaming-rpc)
- [WebSocket API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Wav2Vec 2.0 Paper](https://arxiv.org/abs/2006.11477)

---

> **ë‹¤ìŒ í•™ìŠµ**: Vue.js â†’ React ì „í™˜ ê²½í—˜ ë° ìƒíƒœê´€ë¦¬ íŒ¨í„´
