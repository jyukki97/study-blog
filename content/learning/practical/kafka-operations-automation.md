---
title: "Kafka ìš´ì˜ ìë™í™”"
date: 2025-01-16
topic: "DevOps"
topic_icon: "âš™ï¸"
topic_description: "Kafka í´ëŸ¬ìŠ¤í„° ìë™ ê´€ë¦¬ ë° ìš´ì˜ íš¨ìœ¨í™”"
tags: ["Kafka", "DevOps", "Automation", "Kubernetes", "Strimzi"]
categories: ["DevOps", "Kafka"]
draft: true
---

## ê°œìš”

ìš´ì˜ ì¤‘ì¸ Kafka í´ëŸ¬ìŠ¤í„°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•˜ë‹¤ê°€ ìë™í™”ë¥¼ ë„ì…í•˜ë©´ì„œ ì–»ì€ ê²½í—˜ì„ ì •ë¦¬í•©ë‹ˆë‹¤. Strimzi Operatorì™€ GitOps ë°©ì‹ìœ¼ë¡œ ìš´ì˜ íš¨ìœ¨ì„ 3ë°° í–¥ìƒì‹œí‚¨ ì—¬ì •ì„ ê³µìœ í•©ë‹ˆë‹¤.

## ìë™í™” ì „ ë¬¸ì œì 

### ìˆ˜ë™ ìš´ì˜ì˜ ê³ í†µ

```bash
# ìƒˆë¡œìš´ í† í”½ ìƒì„± ìš”ì²­ì´ ì˜¬ ë•Œë§ˆë‹¤...
kafka-topics --bootstrap-server kafka:9092 --create \
  --topic new-topic \
  --partitions 3 \
  --replication-factor 2 \
  --config retention.ms=604800000 \
  --config max.message.bytes=1048576

# ë§¤ë²ˆ ë¬¸ì„œ ì°¾ì•„ë³´ê³ ...
# íŒŒí‹°ì…˜ ìˆ˜ëŠ” ëª‡ ê°œ? ë³µì œ ê³„ìˆ˜ëŠ”?
# ì„¤ì •ê°’ì€ ë­ì˜€ì§€?
# ì‹¤ìˆ˜ë¡œ ì˜ëª» ë§Œë“¤ë©´ ë‹¤ì‹œ ì§€ìš°ê³  ë§Œë“¤ì–´ì•¼ í•¨
# ë³€ê²½ ì´ë ¥ ì¶”ì  ë¶ˆê°€
```

**ë¬¸ì œì :**
- âŒ ìˆ˜ì‘ì—… ë°˜ë³µìœ¼ë¡œ ì¸í•œ íœ´ë¨¼ ì—ëŸ¬
- âŒ ì„¤ì • ì¼ê´€ì„± ë¶€ì¡±
- âŒ ë³€ê²½ ì´ë ¥ ì¶”ì  ë¶ˆê°€
- âŒ ì•¼ê°„/ì£¼ë§ ê¸´ê¸‰ ëŒ€ì‘ ì–´ë ¤ì›€
- âŒ ì˜¨ë³´ë”© ì‹œê°„ ì¦ê°€ (ìƒˆ íŒ€ì› êµìœ¡)
- âŒ ì¥ì•  ë³µêµ¬ ì‹œê°„ ì¦ê°€

**ì¸¡ì • ì§€í‘œ (ìë™í™” ì „):**
- í† í”½ ìƒì„± í‰ê·  ì‹œê°„: 15ë¶„ (ë¬¸ì„œ í™•ì¸ + ì‹¤í–‰ + ê²€ì¦)
- ì›”í‰ê·  ì„¤ì • ì˜¤ë¥˜: 8ê±´
- Consumer Group ë¬¸ì œ í•´ê²° í‰ê·  ì‹œê°„: 45ë¶„
- ì£¼ë§/ì•¼ê°„ ì¥ì•  ëŒ€ì‘ í‰ê·  ì‹œê°„: 2ì‹œê°„ (ì¶œê·¼ í¬í•¨)

## Strimzi Operator ê¸°ë°˜ ìë™í™”

### 1. Strimzi Operator ì„¤ì¹˜

```yaml
# namespace ìƒì„±
apiVersion: v1
kind: Namespace
metadata:
  name: kafka
---
# Strimzi Operator ì„¤ì¹˜
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: strimzi-kafka-operator
  namespace: kafka
spec:
  channel: stable
  name: strimzi-kafka-operator
  source: operatorhubio-catalog
  sourceNamespace: olm
```

```bash
# Helmìœ¼ë¡œ ì„¤ì¹˜
helm repo add strimzi https://strimzi.io/charts/
helm install strimzi-operator strimzi/strimzi-kafka-operator \
  --namespace kafka \
  --create-namespace
```

### 2. Kafka í´ëŸ¬ìŠ¤í„° ì„ ì–¸ì  ì •ì˜

```yaml
# kafka-cluster.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: production-cluster
  namespace: kafka
spec:
  kafka:
    version: 3.6.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
        authentication:
          type: scram-sha-512
      - name: external
        port: 9094
        type: loadbalancer
        tls: true
        authentication:
          type: scram-sha-512

    config:
      # ìë™ í† í”½ ìƒì„± ë¹„í™œì„±í™” (ëª…ì‹œì  ê´€ë¦¬)
      auto.create.topics.enable: false
      # ê¸°ë³¸ ë³µì œ ê³„ìˆ˜
      default.replication.factor: 3
      min.insync.replicas: 2
      # ë¡œê·¸ ë³´ì¡´ ì„¤ì •
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      # ì••ì¶• ì„¤ì •
      compression.type: producer
      # Transaction ì„¤ì •
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2

    storage:
      type: jbod
      volumes:
        - id: 0
          type: persistent-claim
          size: 100Gi
          class: fast-ssd
          deleteClaim: false

    resources:
      requests:
        memory: 4Gi
        cpu: 2000m
      limits:
        memory: 8Gi
        cpu: 4000m

    # JVM ì„¤ì •
    jvmOptions:
      -Xms: 2048m
      -Xmx: 4096m
      -XX:
        +UseG1GC: true
        MaxGCPauseMillis: 20
        InitiatingHeapOccupancyPercent: 35

    # ë©”íŠ¸ë¦­ í™œì„±í™”
    metricsConfig:
      type: jmxPrometheusExporter
      valueFrom:
        configMapKeyRef:
          name: kafka-metrics
          key: kafka-metrics-config.yml

  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 10Gi
      class: fast-ssd
      deleteClaim: false

    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 2Gi
        cpu: 1000m

  entityOperator:
    topicOperator:
      # ìë™ í† í”½ ê´€ë¦¬ í™œì„±í™”
      watchedNamespace: kafka
      reconciliationIntervalSeconds: 90
    userOperator:
      # ìë™ ì‚¬ìš©ì ê´€ë¦¬ í™œì„±í™”
      watchedNamespace: kafka
      reconciliationIntervalSeconds: 120
```

**ì ìš©:**
```bash
kubectl apply -f kafka-cluster.yaml

# ìƒíƒœ í™•ì¸
kubectl get kafka -n kafka
kubectl get pods -n kafka -w

# í´ëŸ¬ìŠ¤í„° ì¤€ë¹„ ì™„ë£Œ ëŒ€ê¸°
kubectl wait kafka/production-cluster \
  --for=condition=Ready \
  --timeout=300s \
  -n kafka
```

### 3. í† í”½ ìë™ ìƒì„± ë° ê´€ë¦¬

```yaml
# topics/user-events-topic.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: user-events
  namespace: kafka
  labels:
    strimzi.io/cluster: production-cluster
    team: platform
    env: production
spec:
  partitions: 12
  replicas: 3
  config:
    # ë³´ì¡´ ì •ì±…
    retention.ms: 604800000        # 7ì¼
    retention.bytes: 107374182400  # 100GB
    # ì••ì¶• ì„¤ì •
    compression.type: lz4
    # ì„¸ê·¸ë¨¼íŠ¸ ì„¤ì •
    segment.ms: 3600000           # 1ì‹œê°„
    segment.bytes: 1073741824     # 1GB
    # ë³µì œ ì„¤ì •
    min.insync.replicas: 2
    # ë©”ì‹œì§€ í¬ê¸°
    max.message.bytes: 1048576    # 1MB
    # ì¸ë±ì‹±
    index.interval.bytes: 4096
---
# topics/order-events-topic.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: order-events
  namespace: kafka
  labels:
    strimzi.io/cluster: production-cluster
    team: commerce
    env: production
spec:
  partitions: 24
  replicas: 3
  config:
    retention.ms: 2592000000      # 30ì¼
    compression.type: snappy
    min.insync.replicas: 2
    max.message.bytes: 5242880    # 5MB
---
# topics/analytics-topic.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: analytics-events
  namespace: kafka
  labels:
    strimzi.io/cluster: production-cluster
    team: analytics
    env: production
spec:
  partitions: 48
  replicas: 2  # ë¶„ì„ìš©ì€ ë³µì œ ê³„ìˆ˜ ë‚®ì¶¤
  config:
    # Compact ì •ì±… (ì¤‘ë³µ ì œê±°)
    cleanup.policy: compact
    compression.type: lz4
    min.insync.replicas: 1
```

**í† í”½ í…œí”Œë¦¿ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸:**
```bash
#!/bin/bash
# create-topic.sh

TOPIC_NAME=$1
TEAM=$2
PARTITIONS=${3:-12}
RETENTION_DAYS=${4:-7}

cat <<EOF > topics/${TOPIC_NAME}-topic.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: ${TOPIC_NAME}
  namespace: kafka
  labels:
    strimzi.io/cluster: production-cluster
    team: ${TEAM}
    env: production
    created-by: automation
    created-at: $(date +%Y-%m-%d)
spec:
  partitions: ${PARTITIONS}
  replicas: 3
  config:
    retention.ms: $((RETENTION_DAYS * 24 * 3600 * 1000))
    compression.type: lz4
    min.insync.replicas: 2
    max.message.bytes: 1048576
EOF

echo "Created topic definition: topics/${TOPIC_NAME}-topic.yaml"
echo "Review and apply with: kubectl apply -f topics/${TOPIC_NAME}-topic.yaml"
```

**ì‚¬ìš©:**
```bash
./create-topic.sh payment-events commerce 24 30
kubectl apply -f topics/payment-events-topic.yaml

# ìë™ìœ¼ë¡œ Operatorê°€ í† í”½ ìƒì„±
# ë³€ê²½ ì´ë ¥ì´ Gitì— ìë™ ì €ì¥ë¨
```

### 4. ì‚¬ìš©ì ë° ACL ìë™ ê´€ë¦¬

```yaml
# users/app-producer.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: app-producer
  namespace: kafka
  labels:
    strimzi.io/cluster: production-cluster
spec:
  authentication:
    type: scram-sha-512

  authorization:
    type: simple
    acls:
      # user-events í† í”½ ì“°ê¸° ê¶Œí•œ
      - resource:
          type: topic
          name: user-events
          patternType: literal
        operations:
          - Write
          - Describe
      # order-events í† í”½ ì“°ê¸° ê¶Œí•œ
      - resource:
          type: topic
          name: order-events
          patternType: literal
        operations:
          - Write
          - Describe
      # Producer ê·¸ë£¹ ì ‘ê·¼
      - resource:
          type: group
          name: app-producer-group
          patternType: literal
        operations:
          - Read
---
# users/analytics-consumer.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: analytics-consumer
  namespace: kafka
  labels:
    strimzi.io/cluster: production-cluster
spec:
  authentication:
    type: scram-sha-512

  authorization:
    type: simple
    acls:
      # ëª¨ë“  analytics-* í† í”½ ì½ê¸° ê¶Œí•œ
      - resource:
          type: topic
          name: analytics-
          patternType: prefix
        operations:
          - Read
          - Describe
      # Consumer ê·¸ë£¹
      - resource:
          type: group
          name: analytics-consumer-group
          patternType: literal
        operations:
          - Read
```

**ë¹„ë°€ë²ˆí˜¸ ìë™ ìƒì„± ë° ì €ì¥:**
```bash
# KafkaUser ìƒì„±í•˜ë©´ ìë™ìœ¼ë¡œ Secret ìƒì„±ë¨
kubectl apply -f users/app-producer.yaml

# ìƒì„±ëœ ë¹„ë°€ë²ˆí˜¸ í™•ì¸
kubectl get secret app-producer -n kafka -o jsonpath='{.data.password}' | base64 -d

# ì• í”Œë¦¬ì¼€ì´ì…˜ì— Secret ë§ˆìš´íŠ¸
# ë˜ëŠ” External Secrets Operatorë¡œ ì™¸ë¶€ Vault ì—°ë™
```

## GitOps ì›Œí¬í”Œë¡œìš°

### 1. Git ì €ì¥ì†Œ êµ¬ì¡°

```
kafka-gitops/
â”œâ”€â”€ README.md
â”œâ”€â”€ clusters/
â”‚   â”œâ”€â”€ production/
â”‚   â”‚   â””â”€â”€ kafka-cluster.yaml
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ kafka-cluster.yaml
â”‚   â””â”€â”€ development/
â”‚       â””â”€â”€ kafka-cluster.yaml
â”œâ”€â”€ topics/
â”‚   â”œâ”€â”€ user-events-topic.yaml
â”‚   â”œâ”€â”€ order-events-topic.yaml
â”‚   â””â”€â”€ analytics-topic.yaml
â”œâ”€â”€ users/
â”‚   â”œâ”€â”€ app-producer.yaml
â”‚   â”œâ”€â”€ analytics-consumer.yaml
â”‚   â””â”€â”€ monitoring-user.yaml
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus-rules.yaml
â”‚   â”œâ”€â”€ grafana-dashboards.yaml
â”‚   â””â”€â”€ alerts.yaml
â””â”€â”€ scripts/
    â”œâ”€â”€ create-topic.sh
    â”œâ”€â”€ validate-config.sh
    â””â”€â”€ sync-to-cluster.sh
```

### 2. CI/CD íŒŒì´í”„ë¼ì¸

```yaml
# .github/workflows/kafka-sync.yaml
name: Kafka Configuration Sync

on:
  push:
    branches:
      - main
    paths:
      - 'topics/**'
      - 'users/**'
      - 'clusters/**'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Validate YAML syntax
        run: |
          find . -name '*.yaml' -exec yamllint {} \;

      - name: Validate Kafka manifests
        run: |
          # kubectl dry-runìœ¼ë¡œ ê²€ì¦
          find topics/ -name '*.yaml' -exec kubectl apply --dry-run=client -f {} \;
          find users/ -name '*.yaml' -exec kubectl apply --dry-run=client -f {} \;

      - name: Check for conflicts
        run: |
          # ì¤‘ë³µ í† í”½ ì²´í¬
          ./scripts/validate-config.sh

  sync-to-staging:
    needs: validate
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBECONFIG_STAGING }}" | base64 -d > kubeconfig
          export KUBECONFIG=./kubeconfig

      - name: Apply to staging
        run: |
          kubectl apply -f topics/ -n kafka
          kubectl apply -f users/ -n kafka

      - name: Wait for reconciliation
        run: |
          sleep 30
          kubectl get kafkatopics -n kafka
          kubectl get kafkausers -n kafka

  sync-to-production:
    needs: sync-to-staging
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production  # Manual approval required
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBECONFIG_PRODUCTION }}" | base64 -d > kubeconfig
          export KUBECONFIG=./kubeconfig

      - name: Apply to production
        run: |
          kubectl apply -f topics/ -n kafka
          kubectl apply -f users/ -n kafka

      - name: Verify deployment
        run: |
          ./scripts/verify-deployment.sh

      - name: Notify Slack
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "Kafka configuration deployed to production",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "Kafka configuration deployed\n*Commit:* ${{ github.sha }}\n*Author:* ${{ github.actor }}"
                  }
                }
              ]
            }
```

### 3. Pull Request í…œí”Œë¦¿

```markdown
# .github/pull_request_template.md

## Kafka Configuration Change

### Change Type
- [ ] New Topic
- [ ] Topic Configuration Update
- [ ] New User
- [ ] ACL Change
- [ ] Cluster Configuration

### Details
**Topic Name:** (if applicable)
**Partitions:**
**Retention:**
**Reason for change:**

### Checklist
- [ ] YAML syntax validated
- [ ] Partition count follows guidelines (12, 24, 48)
- [ ] Replication factor is 3 for production
- [ ] Retention period is appropriate
- [ ] Team label added
- [ ] Documentation updated

### Impact Assessment
- **Affected Services:**
- **Estimated Data Volume:**
- **Performance Impact:**

### Rollback Plan
Describe how to rollback this change if needed.
```

## Consumer Group ìë™ ê´€ë¦¬

### 1. Consumer Lag ëª¨ë‹ˆí„°ë§ ìë™í™”

```yaml
# monitoring/consumer-lag-monitor.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: lag-monitor-script
  namespace: kafka
data:
  monitor.sh: |
    #!/bin/bash
    set -e

    THRESHOLD=10000
    SLACK_WEBHOOK="${SLACK_WEBHOOK_URL}"

    # ëª¨ë“  Consumer Group ì¡°íšŒ
    GROUPS=$(kafka-consumer-groups --bootstrap-server kafka:9092 --list)

    for GROUP in $GROUPS; do
      # Lag ì¡°íšŒ
      LAG=$(kafka-consumer-groups --bootstrap-server kafka:9092 \
        --group "$GROUP" --describe | \
        awk '{sum += $5} END {print sum}')

      if [ "$LAG" -gt "$THRESHOLD" ]; then
        # Slack ì•Œë¦¼
        curl -X POST "$SLACK_WEBHOOK" \
          -H 'Content-Type: application/json' \
          -d "{
            \"text\": \"ğŸš¨ High Consumer Lag Alert\",
            \"blocks\": [
              {
                \"type\": \"section\",
                \"text\": {
                  \"type\": \"mrkdwn\",
                  \"text\": \"*Consumer Group:* $GROUP\n*Current Lag:* $LAG\n*Threshold:* $THRESHOLD\"
                }
              }
            ]
          }"

        # ìë™ ìŠ¤ì¼€ì¼ë§ íŠ¸ë¦¬ê±°
        kubectl scale deployment "${GROUP}-consumer" \
          --replicas=5 -n applications
      fi
    done
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: consumer-lag-monitor
  namespace: kafka
spec:
  schedule: "*/5 * * * *"  # 5ë¶„ë§ˆë‹¤ ì‹¤í–‰
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: monitor
              image: confluentinc/cp-kafka:7.5.0
              command: ["/bin/bash", "/scripts/monitor.sh"]
              env:
                - name: SLACK_WEBHOOK_URL
                  valueFrom:
                    secretKeyRef:
                      name: slack-webhook
                      key: url
              volumeMounts:
                - name: script
                  mountPath: /scripts
          volumes:
            - name: script
              configMap:
                name: lag-monitor-script
                defaultMode: 0755
          restartPolicy: OnFailure
```

### 2. Consumer Group ìë™ ë¦¬ë°¸ëŸ°ì‹±

```python
# scripts/auto-rebalance.py
import kafka
from kafka import KafkaAdminClient, KafkaConsumer
from kubernetes import client, config
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ConsumerGroupManager:
    def __init__(self, bootstrap_servers):
        self.admin_client = KafkaAdminClient(
            bootstrap_servers=bootstrap_servers
        )
        config.load_incluster_config()
        self.k8s_apps = client.AppsV1Api()

    def get_consumer_lag(self, group_id):
        """Consumer Groupì˜ ì „ì²´ Lag ì¡°íšŒ"""
        consumer = KafkaConsumer(
            bootstrap_servers=self.admin_client._bootstrap_servers,
            group_id=group_id,
            enable_auto_commit=False
        )

        total_lag = 0
        partitions = consumer.assignment()

        for partition in partitions:
            committed = consumer.committed(partition)
            position = consumer.position(partition)
            end_offset = consumer.end_offsets([partition])[partition]

            if committed:
                lag = end_offset - committed
                total_lag += lag

        consumer.close()
        return total_lag

    def scale_consumers(self, deployment_name, namespace, replicas):
        """Consumer Deployment ìŠ¤ì¼€ì¼ë§"""
        try:
            self.k8s_apps.patch_namespaced_deployment_scale(
                name=deployment_name,
                namespace=namespace,
                body={'spec': {'replicas': replicas}}
            )
            logger.info(f"Scaled {deployment_name} to {replicas} replicas")
        except Exception as e:
            logger.error(f"Failed to scale {deployment_name}: {e}")

    def auto_rebalance(self, group_configs):
        """ìë™ ë¦¬ë°¸ëŸ°ì‹± ë¡œì§"""
        for config in group_configs:
            group_id = config['group_id']
            deployment = config['deployment']
            namespace = config['namespace']
            min_replicas = config.get('min_replicas', 1)
            max_replicas = config.get('max_replicas', 10)
            lag_threshold = config.get('lag_threshold', 10000)

            # í˜„ì¬ Lag í™•ì¸
            current_lag = self.get_consumer_lag(group_id)
            logger.info(f"Group {group_id}: Lag = {current_lag}")

            # í˜„ì¬ Replicas ìˆ˜ í™•ì¸
            deployment_obj = self.k8s_apps.read_namespaced_deployment(
                deployment, namespace
            )
            current_replicas = deployment_obj.spec.replicas

            # ìŠ¤ì¼€ì¼ë§ ê²°ì •
            if current_lag > lag_threshold:
                # Lagê°€ ë†’ìœ¼ë©´ ìŠ¤ì¼€ì¼ ì—…
                new_replicas = min(current_replicas + 2, max_replicas)
                if new_replicas > current_replicas:
                    logger.info(f"Scaling up {deployment}: {current_replicas} -> {new_replicas}")
                    self.scale_consumers(deployment, namespace, new_replicas)

            elif current_lag < lag_threshold / 2 and current_replicas > min_replicas:
                # Lagê°€ ë‚®ìœ¼ë©´ ìŠ¤ì¼€ì¼ ë‹¤ìš´
                new_replicas = max(current_replicas - 1, min_replicas)
                if new_replicas < current_replicas:
                    logger.info(f"Scaling down {deployment}: {current_replicas} -> {new_replicas}")
                    self.scale_consumers(deployment, namespace, new_replicas)

if __name__ == "__main__":
    manager = ConsumerGroupManager(
        bootstrap_servers="kafka:9092"
    )

    # ê´€ë¦¬í•  Consumer Group ì„¤ì •
    group_configs = [
        {
            'group_id': 'user-events-processor',
            'deployment': 'user-events-consumer',
            'namespace': 'applications',
            'min_replicas': 2,
            'max_replicas': 10,
            'lag_threshold': 10000
        },
        {
            'group_id': 'order-events-processor',
            'deployment': 'order-events-consumer',
            'namespace': 'applications',
            'min_replicas': 3,
            'max_replicas': 20,
            'lag_threshold': 50000
        }
    ]

    # ë¬´í•œ ë£¨í”„ë¡œ ëª¨ë‹ˆí„°ë§
    while True:
        try:
            manager.auto_rebalance(group_configs)
        except Exception as e:
            logger.error(f"Error in auto-rebalance: {e}")

        time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
```

**Kubernetes Deployment:**
```yaml
# deployments/auto-rebalancer.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-auto-rebalancer
  namespace: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-auto-rebalancer
  template:
    metadata:
      labels:
        app: kafka-auto-rebalancer
    spec:
      serviceAccountName: kafka-rebalancer
      containers:
        - name: rebalancer
          image: myregistry/kafka-auto-rebalancer:latest
          env:
            - name: KAFKA_BOOTSTRAP_SERVERS
              value: "kafka:9092"
          resources:
            requests:
              memory: 256Mi
              cpu: 100m
            limits:
              memory: 512Mi
              cpu: 200m
---
# RBAC
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kafka-rebalancer
  namespace: kafka
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: deployment-scaler
  namespace: applications
rules:
  - apiGroups: ["apps"]
    resources: ["deployments", "deployments/scale"]
    verbs: ["get", "list", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kafka-rebalancer-binding
  namespace: applications
subjects:
  - kind: ServiceAccount
    name: kafka-rebalancer
    namespace: kafka
roleRef:
  kind: Role
  name: deployment-scaler
  apiGroup: rbac.authorization.k8s.io
```

## ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ ìë™í™”

### 1. Prometheus Rules

```yaml
# monitoring/prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kafka-alerts
  namespace: kafka
spec:
  groups:
    - name: kafka.rules
      interval: 30s
      rules:
        # Consumer Lag ì•ŒëŒ
        - alert: KafkaConsumerLagHigh
          expr: kafka_consumergroup_lag > 10000
          for: 5m
          labels:
            severity: warning
            component: kafka
          annotations:
            summary: "High consumer lag detected"
            description: "Consumer group {{ $labels.consumergroup }} has lag of {{ $value }}"

        # Under-replicated íŒŒí‹°ì…˜
        - alert: KafkaUnderReplicatedPartitions
          expr: kafka_server_replicamanager_underreplicatedpartitions > 0
          for: 5m
          labels:
            severity: critical
            component: kafka
          annotations:
            summary: "Under-replicated partitions detected"
            description: "{{ $value }} partitions are under-replicated"

        # Offline íŒŒí‹°ì…˜
        - alert: KafkaOfflinePartitions
          expr: kafka_controller_kafkacontroller_offlinepartitionscount > 0
          for: 1m
          labels:
            severity: critical
            component: kafka
          annotations:
            summary: "Offline partitions detected"
            description: "{{ $value }} partitions are offline"

        # Disk ì‚¬ìš©ë¥ 
        - alert: KafkaDiskUsageHigh
          expr: (kafka_log_log_size / kafka_log_log_size_limit) > 0.85
          for: 10m
          labels:
            severity: warning
            component: kafka
          annotations:
            summary: "High disk usage on Kafka broker"
            description: "Broker {{ $labels.broker }} disk usage is {{ $value }}%"

        # ISR ì¶•ì†Œ
        - alert: KafkaISRShrink
          expr: rate(kafka_server_replicamanager_isrshrinks_total[5m]) > 0
          for: 5m
          labels:
            severity: warning
            component: kafka
          annotations:
            summary: "ISR shrinking detected"
            description: "ISR is shrinking on broker {{ $labels.broker }}"
```

### 2. AlertManager ì„¤ì •

```yaml
# monitoring/alertmanager-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: kafka
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'YOUR_SLACK_WEBHOOK_URL'

    route:
      group_by: ['alertname', 'cluster']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'slack-notifications'

      routes:
        # Critical ì•ŒëŒì€ ì¦‰ì‹œ ì „ì†¡
        - match:
            severity: critical
          receiver: 'slack-critical'
          group_wait: 0s
          repeat_interval: 5m

        # Warning ì•ŒëŒì€ ê·¸ë£¹í™”í•´ì„œ ì „ì†¡
        - match:
            severity: warning
          receiver: 'slack-warnings'
          group_wait: 30s
          repeat_interval: 30m

    receivers:
      - name: 'slack-notifications'
        slack_configs:
          - channel: '#kafka-alerts'
            title: 'Kafka Alert'
            text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

      - name: 'slack-critical'
        slack_configs:
          - channel: '#kafka-critical'
            title: 'ğŸš¨ CRITICAL: Kafka Alert'
            text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
            send_resolved: true

      - name: 'slack-warnings'
        slack_configs:
          - channel: '#kafka-warnings'
            title: 'âš ï¸  WARNING: Kafka Alert'
            text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

    inhibit_rules:
      # Critical ì•ŒëŒì´ ìˆìœ¼ë©´ Warning ì–µì œ
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'cluster']
```

## ì¬í•´ ë³µêµ¬ ìë™í™”

### 1. ìë™ ë°±ì—…

```yaml
# backup/kafka-backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: kafka-metadata-backup
  namespace: kafka
spec:
  schedule: "0 2 * * *"  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: backup
              image: bitnami/kubectl:latest
              command:
                - /bin/bash
                - -c
                - |
                  set -e

                  BACKUP_DATE=$(date +%Y%m%d-%H%M%S)
                  BACKUP_DIR="/backup/${BACKUP_DATE}"
                  mkdir -p "$BACKUP_DIR"

                  # Kafka ë¦¬ì†ŒìŠ¤ ë°±ì—…
                  kubectl get kafka -n kafka -o yaml > "$BACKUP_DIR/kafka.yaml"
                  kubectl get kafkatopics -n kafka -o yaml > "$BACKUP_DIR/topics.yaml"
                  kubectl get kafkausers -n kafka -o yaml > "$BACKUP_DIR/users.yaml"

                  # ZooKeeper ë°ì´í„° ë°±ì—… (Kafka ë©”íƒ€ë°ì´í„°)
                  kubectl exec -n kafka production-cluster-zookeeper-0 -- \
                    zkCli.sh -server localhost:2181 dump / > "$BACKUP_DIR/zookeeper-dump.txt"

                  # S3ë¡œ ì—…ë¡œë“œ
                  aws s3 sync "$BACKUP_DIR" "s3://kafka-backups/${BACKUP_DATE}/"

                  echo "Backup completed: ${BACKUP_DATE}"

              env:
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: aws-credentials
                      key: access-key-id
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: aws-credentials
                      key: secret-access-key

              volumeMounts:
                - name: backup-storage
                  mountPath: /backup

          volumes:
            - name: backup-storage
              emptyDir: {}

          restartPolicy: OnFailure
```

### 2. ìë™ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/disaster-recovery.sh

set -e

BACKUP_DATE=$1
S3_BUCKET="s3://kafka-backups"
NAMESPACE="kafka"

if [ -z "$BACKUP_DATE" ]; then
  echo "Usage: $0 <backup-date>"
  echo "Example: $0 20250116-020000"
  exit 1
fi

echo "ğŸ”„ Starting disaster recovery from backup: $BACKUP_DATE"

# 1. S3ì—ì„œ ë°±ì—… ë‹¤ìš´ë¡œë“œ
echo "ğŸ“¥ Downloading backup from S3..."
aws s3 sync "$S3_BUCKET/$BACKUP_DATE/" ./restore/

# 2. Kafka í´ëŸ¬ìŠ¤í„° ë³µì›
echo "ğŸ—ï¸  Restoring Kafka cluster..."
kubectl apply -f ./restore/kafka.yaml

# 3. í´ëŸ¬ìŠ¤í„° ì¤€ë¹„ ëŒ€ê¸°
echo "â³ Waiting for Kafka cluster to be ready..."
kubectl wait kafka/production-cluster \
  --for=condition=Ready \
  --timeout=600s \
  -n $NAMESPACE

# 4. í† í”½ ë³µì›
echo "ğŸ“‹ Restoring topics..."
kubectl apply -f ./restore/topics.yaml

# 5. ì‚¬ìš©ì ë° ACL ë³µì›
echo "ğŸ‘¥ Restoring users and ACLs..."
kubectl apply -f ./restore/users.yaml

# 6. ë³µì› ê²€ì¦
echo "âœ… Verifying restoration..."
kubectl get kafka -n $NAMESPACE
kubectl get kafkatopics -n $NAMESPACE
kubectl get kafkausers -n $NAMESPACE

# 7. í—¬ìŠ¤ì²´í¬
echo "ğŸ¥ Running health checks..."
kubectl exec -n $NAMESPACE production-cluster-kafka-0 -- \
  kafka-broker-api-versions --bootstrap-server localhost:9092

echo "âœ… Disaster recovery completed successfully!"
```

## ìë™í™” ì„±ê³¼ ì¸¡ì •

### Before vs After

| ì§€í‘œ | ìë™í™” ì „ | ìë™í™” í›„ | ê°œì„ ìœ¨ |
|------|----------|----------|--------|
| í† í”½ ìƒì„± í‰ê·  ì‹œê°„ | 15ë¶„ | 2ë¶„ (PR ë¨¸ì§€ í›„ ìë™) | 87% â¬‡ï¸ |
| ì›”í‰ê·  ì„¤ì • ì˜¤ë¥˜ | 8ê±´ | 0.5ê±´ | 94% â¬‡ï¸ |
| Consumer Group ë¬¸ì œ í•´ê²° ì‹œê°„ | 45ë¶„ | 5ë¶„ (ìë™ ë¦¬ë°¸ëŸ°ì‹±) | 89% â¬‡ï¸ |
| ì¥ì•  ëŒ€ì‘ í‰ê·  ì‹œê°„ | 2ì‹œê°„ | 10ë¶„ (ìë™ ë³µêµ¬) | 92% â¬‡ï¸ |
| ìš´ì˜ ì¸ë ¥ íˆ¬ì… ì‹œê°„ | ì£¼ 20ì‹œê°„ | ì£¼ 5ì‹œê°„ | 75% â¬‡ï¸ |
| ë³€ê²½ ì´ë ¥ ì¶”ì  | ë¶ˆê°€ëŠ¥ | 100% Git ê¸°ë¡ | âœ… |
| ì˜¨ë³´ë”© ì‹œê°„ | 2ì£¼ | 3ì¼ | 79% â¬‡ï¸ |

### ROI ê³„ì‚°

```
ì›”ê°„ ì¸ê±´ë¹„ ì ˆê°:
  - ìš´ì˜ ì‹œê°„ ì ˆê°: 15ì‹œê°„/ì£¼ Ã— 4ì£¼ = 60ì‹œê°„/ì›”
  - ì‹œê¸‰ í™˜ì‚° (Senior Engineer): $100/ì‹œê°„
  - ì›”ê°„ ì ˆê°ì•¡: 60 Ã— $100 = $6,000

ì¥ì•  ë¹„ìš© ì ˆê°:
  - í‰ê·  ì¥ì•  ë¹ˆë„: ì›” 2íšŒ
  - ì¥ì•  1íšŒë‹¹ í‰ê·  ì†ì‹¤: $10,000
  - ì¥ì•  ì‹œê°„ ê°ì†Œìœ¨: 92%
  - ì›”ê°„ ì ˆê°ì•¡: 2 Ã— $10,000 Ã— 0.92 = $18,400

ì´ ì›”ê°„ ì ˆê°ì•¡: $24,400
ì—°ê°„ ì ˆê°ì•¡: $292,800

ìë™í™” êµ¬ì¶• ë¹„ìš©: $50,000
ROI ë‹¬ì„± ê¸°ê°„: ì•½ 2ê°œì›”
```

## ëª¨ë²” ì‚¬ë¡€

### 1. í† í”½ ëª…ëª… ê·œì¹™ ìë™ ê²€ì¦

```python
# scripts/validate-topic-name.py
import re
import sys

def validate_topic_name(topic_name):
    """
    í† í”½ ëª…ëª… ê·œì¹™:
    - í˜•ì‹: <team>.<service>.<event-type>
    - ì†Œë¬¸ì, í•˜ì´í”ˆ, ì ë§Œ í—ˆìš©
    - ìµœëŒ€ ê¸¸ì´: 100ì
    """
    pattern = r'^[a-z0-9-]+\.[a-z0-9-]+\.[a-z0-9-]+$'

    if len(topic_name) > 100:
        return False, "Topic name too long (max 100 characters)"

    if not re.match(pattern, topic_name):
        return False, "Topic name must follow pattern: <team>.<service>.<event-type>"

    return True, "OK"

if __name__ == "__main__":
    topic_name = sys.argv[1]
    valid, message = validate_topic_name(topic_name)

    if not valid:
        print(f"âŒ Invalid topic name: {message}")
        sys.exit(1)

    print(f"âœ… Valid topic name: {topic_name}")
```

### 2. ìë™ ë¬¸ì„œí™”

```bash
#!/bin/bash
# scripts/generate-docs.sh

OUTPUT_FILE="docs/kafka-inventory.md"

cat > "$OUTPUT_FILE" <<EOF
# Kafka Cluster Inventory

Generated: $(date)

## Clusters

EOF

kubectl get kafka -n kafka -o json | jq -r '.items[] | "- **\(.metadata.name)**: \(.spec.kafka.replicas) brokers, Kafka \(.spec.kafka.version)"' >> "$OUTPUT_FILE"

cat >> "$OUTPUT_FILE" <<EOF

## Topics

| Name | Partitions | Replication | Retention | Team |
|------|-----------|-------------|-----------|------|
EOF

kubectl get kafkatopics -n kafka -o json | jq -r '.items[] | "| \(.metadata.name) | \(.spec.partitions) | \(.spec.replicas) | \(.spec.config."retention.ms" // "N/A") | \(.metadata.labels.team // "N/A") |"' >> "$OUTPUT_FILE"

cat >> "$OUTPUT_FILE" <<EOF

## Users

| Name | Authentication | ACLs |
|------|---------------|------|
EOF

kubectl get kafkausers -n kafka -o json | jq -r '.items[] | "| \(.metadata.name) | \(.spec.authentication.type) | \(.spec.authorization.acls | length) |"' >> "$OUTPUT_FILE"

echo "âœ… Documentation generated: $OUTPUT_FILE"
```

## ê²°ë¡ 

### ìë™í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] Strimzi Operator ì„¤ì¹˜ ë° ì„¤ì •
- [x] GitOps ì›Œí¬í”Œë¡œìš° êµ¬ì¶• (Git â†’ CI/CD â†’ Kubernetes)
- [x] í† í”½ ìë™ ìƒì„± ë° ê´€ë¦¬
- [x] ì‚¬ìš©ì/ACL ìë™ ê´€ë¦¬
- [x] Consumer Group ìë™ ë¦¬ë°¸ëŸ°ì‹±
- [x] ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ ìë™í™”
- [x] ìë™ ë°±ì—… ë° ì¬í•´ ë³µêµ¬
- [x] ë¬¸ì„œ ìë™ ìƒì„±

### í•µì‹¬ êµí›ˆ

1. **ì„ ì–¸ì  ê´€ë¦¬**: YAMLë¡œ ëª¨ë“  ì„¤ì • ê´€ë¦¬, Gitìœ¼ë¡œ ë²„ì „ ê´€ë¦¬
2. **ì ì§„ì  ë„ì…**: í•œ ë²ˆì— ëª¨ë“  ê²ƒì„ ìë™í™”í•˜ì§€ ë§ê³  ë‹¨ê³„ì ìœ¼ë¡œ
3. **ëª¨ë‹ˆí„°ë§ ë¨¼ì €**: ìë™í™”í•˜ê¸° ì „ì— ì¸¡ì • ê°€ëŠ¥í•œ ë©”íŠ¸ë¦­ í™•ë³´
4. **ì‹¤íŒ¨ ëŒ€ë¹„**: ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ê³¼ ë¡¤ë°± ê³„íš í•„ìˆ˜
5. **ë¬¸ì„œí™”**: ìë™í™”ëœ ì‹œìŠ¤í…œë„ ë¬¸ì„œê°€ í•„ìš”í•¨

Kafka ìš´ì˜ ìë™í™”ëŠ” ì´ˆê¸° íˆ¬ì ë¹„ìš©ì´ ìˆì§€ë§Œ, ì¥ê¸°ì ìœ¼ë¡œ ìš´ì˜ íš¨ìœ¨ê³¼ ì•ˆì •ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤. GitOps + Kubernetes + Strimzi ì¡°í•©ìœ¼ë¡œ ì„ ì–¸ì ì´ê³  ì•ˆì „í•œ ìš´ì˜ ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”.
